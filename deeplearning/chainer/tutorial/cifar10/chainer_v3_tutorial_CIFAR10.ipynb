{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import chainer \n",
    "import chainer.links as L \n",
    "import chainer.functions as F\n",
    "from chainer.datasets import cifar\n",
    "from chainer import optimizers\n",
    "from chainer import iterators\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "from ipywidgets import interact\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "if chainer.cuda.available:\n",
    "    chainer.cuda.cupy.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_out):\n",
    "        super(MyNet, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(None, 32, 3, 3, 1)\n",
    "            self.conv2 = L.Convolution2D(32, 64, 3, 3, 1)\n",
    "            self.conv3 = L.Convolution2D(64, 128, 3, 3, 1)\n",
    "            self.fc4 = L.Linear(None, 1000)\n",
    "            self.fc5 = L.Linear(1000, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.relu(self.fc4(h))\n",
    "        h = self.fc5(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, \n",
    "          batchsize=128,\n",
    "          device=0,\n",
    "          max_epoch=20,\n",
    "          train_dataset=None,\n",
    "          test_dataset=None,\n",
    "          postfix='',\n",
    "          base_lr=0.01, \n",
    "          lr_decay=None):\n",
    "    if train_dataset is None and test_dataset is None:\n",
    "        train, test = cifar.get_cifar10()\n",
    "    else:\n",
    "        train, test = train_dataset, test_dataset \n",
    "    \n",
    "    train_iter = iterators.MultiprocessIterator(train, batchsize)\n",
    "    test_iter = iterators.MultiprocessIterator(test, batchsize, False, False)\n",
    "    \n",
    "    classifier = L.Classifier(network)\n",
    "    \n",
    "    optimizer = optimizers.MomentumSGD(lr=base_lr)\n",
    "    optimizer.setup(classifier)\n",
    "    optimizer.add_hook(chainer.optimizer.WeightDecay(0.0005))\n",
    "    \n",
    "    updater = training.StandardUpdater(train_iter, optimizer, device=device)\n",
    "    trainer = training.Trainer(updater,\n",
    "                              (max_epoch, 'epoch'),\n",
    "                               out='{}_cifar10_{}result'.format(network.__class__.__name__,postfix))\n",
    "    trainer.extend(extensions.LogReport())\n",
    "    trainer.extend(extensions.observe_lr())\n",
    "    trainer.extend(extensions.Evaluator(test_iter, classifier, device=device), name='val')\n",
    "    trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'val/main/loss', 'val/main/accuracy', 'elapsed_time', 'lr']))\n",
    "    trainer.extend(extensions.PlotReport(['main/loss', 'val/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "    trainer.extend(extensions.PlotReport(['main/accuracy', 'val/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "    if lr_decay is not None:\n",
    "        trainer.extend(extensions.ExponentialShift('lr',0.1), trigger=lr_decay)\n",
    "    trainer.run()\n",
    "    return classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = train(MyNet(10), device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='MyNet_cifar10_result/loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='MyNet_cifar10_result/accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データでの精度（main/accuracy)は87%程度まで到達していますが、テストデータでのロス（val/main/loss）はむしろIterationを進むごとに大きくなってしまっており、またテストデータでの精度（val/main/accuracy）も60%前後で頭打ちになってしまっています。学習データでは良い精度が出ているが、テストデータでは精度が良くないということなので、モデルが学習データにオーバーフィッティングしていると思われます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klass_name = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "             'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "_, test = cifar.get_cifar10()\n",
    "\n",
    "def predict(net, image_id):\n",
    "    x, t = test[image_id]\n",
    "    net.to_cpu()\n",
    "    y = net.predictor(x[None, ...]).data.argmax(axis=1)[0]\n",
    "    print('predicted_label:', klass_name[y])\n",
    "    print('answer:', klass_name[t])\n",
    "    plt.imshow(x.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(lambda image_id:predict(classifier, image_id), image_id=list(range(len(test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(chainer.Chain):\n",
    "    def __init__(self, n_ch, pool_drop=False):\n",
    "        w = chainer.initializers.HeNormal()\n",
    "        super(ConvBlock, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv=L.Convolution2D(None, n_ch, 3, 1, 1, nobias=True, initialW=w)\n",
    "            self.bn = L.BatchNormalization(n_ch)\n",
    "        self.pool_drop = pool_drop\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.bn(self.conv(x)))\n",
    "        if self.pool_drop:\n",
    "            h=F.max_pooling_2d(h, 2, 2)\n",
    "            h=F.dropout(h, ratio=0.25)\n",
    "        return h \n",
    "    \n",
    "class LinearBlock(chainer.Chain):\n",
    "    def __init__(self, drop=True):\n",
    "        w=chainer.initializers.HeNormal()\n",
    "        super(LinearBlock, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.fc=L.Linear(None, 1024,initialW=w)\n",
    "        self.drop = drop \n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.fc(x))\n",
    "        if self.drop:\n",
    "            h = F.dropout(h)\n",
    "        return h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNN(chainer.ChainList):\n",
    "\n",
    "    def __init__(self, n_output):\n",
    "        super(DeepCNN, self).__init__(\n",
    "            ConvBlock(64),\n",
    "            ConvBlock(64, True),\n",
    "            ConvBlock(128),\n",
    "            ConvBlock(128, True),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256, True),\n",
    "            LinearBlock(),\n",
    "            LinearBlock(),\n",
    "            L.Linear(None, n_output)\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for f in self:\n",
    "            x = f(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(DeepCNN(10), max_epoch=100, base_lr=0.1, lr_decay=(30, 'epoch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='DeepCNN_cifar10_result/loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='DeepCNN_cifar10_result/accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Augmented(chainer.dataset.DatasetMixin):\n",
    "\n",
    "    def __init__(self, train=True):\n",
    "        train_data, test_data = cifar.get_cifar10()\n",
    "        if train:\n",
    "            self.data = train_data\n",
    "        else:\n",
    "            self.data = test_data\n",
    "        self.train = train\n",
    "        self.random_crop = 4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        x, t = self.data[i]\n",
    "        if self.train:\n",
    "            x = x.transpose(1, 2, 0)\n",
    "            h, w, _ = x.shape\n",
    "            x_offset = np.random.randint(self.random_crop)\n",
    "            y_offset = np.random.randint(self.random_crop)\n",
    "            x = x[y_offset:y_offset + h - self.random_crop,\n",
    "                  x_offset:x_offset + w - self.random_crop]\n",
    "            if np.random.rand() > 0.5:\n",
    "                x = np.fliplr(x)\n",
    "            x = x.transpose(2, 0, 1)\n",
    "\n",
    "        return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(DeepCNN(10), max_epoch=100, train_dataset=CIFAR10Augmented(), test_dataset=CIFAR10Augmented(False), postfix='augmented_', base_lr=0.1, lr_decay=(30, 'epoch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='DeepCNN_cifar10_augmented_result/loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='DeepCNN_cifar10_augmented_result/accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.datasets import TransformDataset\n",
    "\n",
    "train_dataset, test_dataset = cifar.get_cifar10()\n",
    "\n",
    "\n",
    "# 行いたい変換を関数の形で書く\n",
    "def transform(inputs):\n",
    "    x, t = inputs\n",
    "    x = x.transpose(1, 2, 0)\n",
    "    h, w, _ = x.shape\n",
    "    x_offset = np.random.randint(4)\n",
    "    y_offset = np.random.randint(4)\n",
    "    x = x[y_offset:y_offset + h - 4,\n",
    "          x_offset:x_offset + w - 4]\n",
    "    if np.random.rand() > 0.5:\n",
    "        x = np.fliplr(x)\n",
    "    x = x.transpose(2, 0, 1)\n",
    "\n",
    "    return x, t\n",
    "\n",
    "\n",
    "# 各データをtransformにくぐらせたものを返すデータセットオブジェクト\n",
    "train_dataset = TransformDataset(train_dataset, transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
